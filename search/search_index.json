{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Welcome to the LETO MVP docs \u00b6 In this documentation, you will find the necessary instructions to set up and interact with the LETO application. Warning LETO is a work-in-progress, and it's currently not suitable for production use. Everything in this documentation can change at any time until the APIs are stable. Quick start \u00b6 The easiest way to get LETO up and running is to clone the source code repository and spin up the development environment. You will need docker and git installed. If you are on Linux, there's a makefile ready for you. $ git clone https://github.com/LETO-ai/leto-mvp $ make The previous command will spin up an instance of the LETO UI, the neo4j backend, and these docs. Then navigate to to interact with the UI. Note Refer to the user guide for details about using the application. Collaboration \u00b6 In LETO, we use trunk-based development. Developers use short-lived branches, which are pushed to the central repository and merged back to the main branch as quickly as possible. For development, you will need Visual Studio Code or another suitable editor. You will work in the development environment described in the previous section. Note Refer to the development guide for more details.","title":"\ud83c\udfe0 Home"},{"location":"#welcome-to-the-leto-mvp-docs","text":"In this documentation, you will find the necessary instructions to set up and interact with the LETO application. Warning LETO is a work-in-progress, and it's currently not suitable for production use. Everything in this documentation can change at any time until the APIs are stable.","title":"Welcome to the LETO MVP docs"},{"location":"#quick-start","text":"The easiest way to get LETO up and running is to clone the source code repository and spin up the development environment. You will need docker and git installed. If you are on Linux, there's a makefile ready for you. $ git clone https://github.com/LETO-ai/leto-mvp $ make The previous command will spin up an instance of the LETO UI, the neo4j backend, and these docs. Then navigate to to interact with the UI. Note Refer to the user guide for details about using the application.","title":"Quick start"},{"location":"#collaboration","text":"In LETO, we use trunk-based development. Developers use short-lived branches, which are pushed to the central repository and merged back to the main branch as quickly as possible. For development, you will need Visual Studio Code or another suitable editor. You will work in the development environment described in the previous section. Note Refer to the development guide for more details.","title":"Collaboration"},{"location":"dev/","text":"Welcome to LETO's development guide \u00b6 This guide explains LETO's architecture and guidelines on how to extend and modify it. Overview of LETO's architecture \u00b6 At the highest level, LETO is an application composed of two services: a frontend written in streamlit and a backend stored in neo4j . All the data is LETO is stored in a single graph database in neo4j , using some conventions to determine how it is interpreted. The frontend is a streamlit app which follows a very simple cycle: Load new data (if necessary) Parse a query Compute a response Visualize the response This cycle is implemented as a streamlined process in leto/ui.py which in turn uses several components to weave everything. Let's look at each step in more detail. Data enters LETO via a Loader , a class that implements a single _load() method that returns an iterable of Entity and Relation instances. An Entity is just a name plus a type, and some opaque attributes. Likewise, a Relation has a label, and the two entities it connects. All relations in LETO are directed. In the main application cycle, the currently selected loader is first instantiated with the corresponding parameters and then executed. The resulting iterable is given to a Storage instance, which can be either GraphStorage (the default) or a DummyStorage (which is there just for testing purposes). An Storage inheritor needs to supply a store method with receives either an entity or a relation. They also provide a size() method for instrospection. Once stored any newly created data, the main application loop proceeds to parse the current query. A QueryParser implementation is used here, which receives a string as input and returns an instance of the Query class. Different sub-instances of Query exist, but they all share the same basic structure: a list of entities, a list of relations, and a list of attributes. Currently implemented query parsers are based on some hard-coded rules on top of a spacy tokenization of the query, hence they perform basic entity detection and the rules are based on POS-tags and other syntactic cues. Once parsed, the query is fed to a QueryResolver instance, which is provided by the Storage implementation. This will return a sub-graph in the form of a list of tuples, i.e., Relation instances. How smart can this resolution be is left to the implementation of the query resolver. In GraphStorage the query resolver generates a set of neo4j queries based on some rules that try to find the most similar entities and relations in the graph. There's also currently a simplistic implementation of a similarity engine using spacy word embeddings, but this is still in a very crude state. Finally, the response (as a list of tuples) is fed to a list of Visualizer instances. Each visualizer has some specific rules that determine whether it applies, and if so, it produces a callable method to be run for generating the actual visualization. For example, the basic graph visualizer just outputs the graph as a pydot image. However, the map visualizer will inspect the tuples to see if it finds something with geographical information, and if so, it generates a map with the corresponding points. Adding new data sources \u00b6 To add a new data source, you need to provide a new implementation of Loader . As explained, this implementation must provide a _load() method which yields Entity or Relation instances one at a time. A Loader also provides a _get_source() method with outputs an entity of type Source . This basically holds metadata that is then linked to all the entities created from the _load() . As an example, here's a dummy implementation that loads data from a manually entered text in the format entity - relation - entity : class ManualLoader ( Loader ): @classmethod def title ( cls ): return \"Manually enter tuples\" def __init__ ( self , tuples : Text ) -> None : self . tuples = tuples def _get_source ( self , name , ** metadata ) -> Source : return Source ( name , method = \"manual\" , loader = \"ManualLoader\" , ** metadata ) def _load ( self ): for line in self . tuples . split ( \" \\n \" ): e1 , r , e2 = line . split ( \"-\" ) e1 = e1 . strip () r = r . strip () e2 = e2 . strip () yield Relation ( label = r , entity_from = Entity ( name = e1 , type = \"Thing\" ), entity_to = Entity ( name = e2 , type = \"Thing\" ), ) Finally, on leto/loaders/__init__.py , method get_loaders() , add a line importing your loader and include it into the returned list. Adding new visualizations \u00b6 To add a new visualization, you need to provide a new implementation of Visualizer . This implementation must provide a method visualize which in turn returns a Visualization instance. A visualization instance basically has title, a score, and a callable method that is invoked when the visualization must be executed. This callable will be run in a streamlit container context, so you can directly use st.* methods to construct any visualization logic you desire. The recommended approach is to implement whatever preprocessing logic is necessary in the visualize() method, and just perform actual visualization logic inside the callback. In the visualize() method, you'll have access to both the original query and the response. The score value is used to sort the visualizations, so you should set it to value that is roughly proportional to how informative the visualization is. This score is unbounded. Here's an example of a very simple visualizer: class DummyVisualizer ( Visualizer ): def visualize ( self , query : Query , response : List [ Relation ]) -> Visualization : def visualization (): st . code ( \" \\n \" . join ( str ( r ) for r in response )) return Visualization ( title = \"\ud83d\udccb Returned tuples\" , score = 0 , run = visualization ) Finally, on leto/visualization/__init__.py , method get_visualizers() add your implementation to the returned list.","title":"\ud83d\udee0\ufe0f Development Guide"},{"location":"dev/#welcome-to-letos-development-guide","text":"This guide explains LETO's architecture and guidelines on how to extend and modify it.","title":"Welcome to LETO's development guide"},{"location":"dev/#overview-of-letos-architecture","text":"At the highest level, LETO is an application composed of two services: a frontend written in streamlit and a backend stored in neo4j . All the data is LETO is stored in a single graph database in neo4j , using some conventions to determine how it is interpreted. The frontend is a streamlit app which follows a very simple cycle: Load new data (if necessary) Parse a query Compute a response Visualize the response This cycle is implemented as a streamlined process in leto/ui.py which in turn uses several components to weave everything. Let's look at each step in more detail. Data enters LETO via a Loader , a class that implements a single _load() method that returns an iterable of Entity and Relation instances. An Entity is just a name plus a type, and some opaque attributes. Likewise, a Relation has a label, and the two entities it connects. All relations in LETO are directed. In the main application cycle, the currently selected loader is first instantiated with the corresponding parameters and then executed. The resulting iterable is given to a Storage instance, which can be either GraphStorage (the default) or a DummyStorage (which is there just for testing purposes). An Storage inheritor needs to supply a store method with receives either an entity or a relation. They also provide a size() method for instrospection. Once stored any newly created data, the main application loop proceeds to parse the current query. A QueryParser implementation is used here, which receives a string as input and returns an instance of the Query class. Different sub-instances of Query exist, but they all share the same basic structure: a list of entities, a list of relations, and a list of attributes. Currently implemented query parsers are based on some hard-coded rules on top of a spacy tokenization of the query, hence they perform basic entity detection and the rules are based on POS-tags and other syntactic cues. Once parsed, the query is fed to a QueryResolver instance, which is provided by the Storage implementation. This will return a sub-graph in the form of a list of tuples, i.e., Relation instances. How smart can this resolution be is left to the implementation of the query resolver. In GraphStorage the query resolver generates a set of neo4j queries based on some rules that try to find the most similar entities and relations in the graph. There's also currently a simplistic implementation of a similarity engine using spacy word embeddings, but this is still in a very crude state. Finally, the response (as a list of tuples) is fed to a list of Visualizer instances. Each visualizer has some specific rules that determine whether it applies, and if so, it produces a callable method to be run for generating the actual visualization. For example, the basic graph visualizer just outputs the graph as a pydot image. However, the map visualizer will inspect the tuples to see if it finds something with geographical information, and if so, it generates a map with the corresponding points.","title":"Overview of LETO's architecture"},{"location":"dev/#adding-new-data-sources","text":"To add a new data source, you need to provide a new implementation of Loader . As explained, this implementation must provide a _load() method which yields Entity or Relation instances one at a time. A Loader also provides a _get_source() method with outputs an entity of type Source . This basically holds metadata that is then linked to all the entities created from the _load() . As an example, here's a dummy implementation that loads data from a manually entered text in the format entity - relation - entity : class ManualLoader ( Loader ): @classmethod def title ( cls ): return \"Manually enter tuples\" def __init__ ( self , tuples : Text ) -> None : self . tuples = tuples def _get_source ( self , name , ** metadata ) -> Source : return Source ( name , method = \"manual\" , loader = \"ManualLoader\" , ** metadata ) def _load ( self ): for line in self . tuples . split ( \" \\n \" ): e1 , r , e2 = line . split ( \"-\" ) e1 = e1 . strip () r = r . strip () e2 = e2 . strip () yield Relation ( label = r , entity_from = Entity ( name = e1 , type = \"Thing\" ), entity_to = Entity ( name = e2 , type = \"Thing\" ), ) Finally, on leto/loaders/__init__.py , method get_loaders() , add a line importing your loader and include it into the returned list.","title":"Adding new data sources"},{"location":"dev/#adding-new-visualizations","text":"To add a new visualization, you need to provide a new implementation of Visualizer . This implementation must provide a method visualize which in turn returns a Visualization instance. A visualization instance basically has title, a score, and a callable method that is invoked when the visualization must be executed. This callable will be run in a streamlit container context, so you can directly use st.* methods to construct any visualization logic you desire. The recommended approach is to implement whatever preprocessing logic is necessary in the visualize() method, and just perform actual visualization logic inside the callback. In the visualize() method, you'll have access to both the original query and the response. The score value is used to sort the visualizations, so you should set it to value that is roughly proportional to how informative the visualization is. This score is unbounded. Here's an example of a very simple visualizer: class DummyVisualizer ( Visualizer ): def visualize ( self , query : Query , response : List [ Relation ]) -> Visualization : def visualization (): st . code ( \" \\n \" . join ( str ( r ) for r in response )) return Visualization ( title = \"\ud83d\udccb Returned tuples\" , score = 0 , run = visualization ) Finally, on leto/visualization/__init__.py , method get_visualizers() add your implementation to the returned list.","title":"Adding new visualizations"},{"location":"guide/","text":"Welcome to LETO's user guide \u00b6 This guide explains how to set up LETO and use its main application UI. Setting up \u00b6 LETO comes packaged with a Docker environment ready to set up. To get started, you need to either clone the project from Github or obtain the source code via a different channel. Once you have the source code in place, cd into the project root and type: make app This command with launch three Docker containers: The main LETO application (\ud83d\udd17 http://localhost:8501 ) A neo4j instance where the backend data is stored (\ud83d\udd17 http://localhost:7474 ) A documentation server, like the one hosting these docs right now (\ud83d\udd17 http://localhost:8000 ) If you're deploying for a production environment, you'll probably want to set up a web server in front of the main application. In that case, you'd need to either modify docker/docker-compose.yml or create a new one (using that file as a starting point) and configure your web server accordingly. Overview of the UI \u00b6 Below is a screenshot of the main LETO application. We'll guide you through the main components one at a time and how to use them. \u2699\ufe0f Basic configuration \u00b6 The top left panel is titled \"\u2699\ufe0f Config\". In this panel, you can configure the backend connection (either using neo4j or a dummy file-based storage driver) and the query parser . If you're using LETO in a language other than English, you will need an appropriate query parser. For now, LETO ships also with a Spanish parser, which you can select in the \"\ud83e\uddd9\u200d\u2642\ufe0f Query parser\" combo. \ud83d\udd25 Loading data \u00b6 LETO runs on data, lots of data. To get data into LETO you'll need to supply one of several possible input types. The panel titled \"\ud83d\udd25 Load new data\" will let you select one of several Loaders that can introduce data to LETO from different formats. Currently, these are the options: Synthetic toy examples : A simple loader that creates a pre-defined small graph which you can use for illustrative purposes. Manually enter tuples : Allows you to explicitly define new entities and relations. From CSV files : Reads data from one or more CSV files, automatically inferring entities and relations based on some simple heuristics. From Text File : Reads natural language from a text file and detects entities and relations using NLP tools. From Plain Text : Same as the previous one, but you can directly type or paste in the text. From Wikipedia page : Given a query string for Wikipedia, this loader downloads the corresponding article and runs NLP tools to detect entities and relations. When you select one specific loader, the UI will change to show its configuration and input. For example, for the file-based loaders you will see a \"Browse files\" button that allows you to select CSV or text files from your filesystem. \ud83d\udd2e Queying LETO \u00b6 Once you have data in the system, LETO can start doing its magic. All the interaction with LETO is through natural language queries. You type a query in main the text input (\"\ud83d\udd2e Enter a query...\") and LETO will navigate through the information stored, collect the most relevant entities and relations for that query, and present that information in one of several formats. The most basic output, as shown in the image, is a subset of the knowledge graph that contains the relevant entities and relations. You will find the most important elements for the query highlighted in different color, e.g., the entities and relations that are explicitly mentioned or those which are very similar. According to the query and the information available, LETO will try to come up with interesting visualizations. For example if there's geographical information in the answer, you'll see it on a map. As an extreme example, a query like \"which features predict salary in Data Scientist\" will make LETO train a simple machine learning model on the available data and graph the feature importances for you. \u2753 Example queries \u00b6 If you've loaded the toy dataset (using the \"Synthetic toy examples\" loader), you can use one of the pre-defined queries at the right side of LETO's main UI. These are premade questions that illustrate the types of queries that can be posted to LETO. Interacting with the backend \u00b6 If you want to interact with the backend data, at http://localhost:7474 you will find neo4j's browser interface. To connect just enter the username neo4j and the password letoai . Neo4j is a graph database that powers all of LETO's queries. Refer to the official documentation for more information on how to use its interface directly. Warning Please keep in mind that if you modify the database outside of LETO (i.e., not using one of LETO's loaders), we cannot guarantee the graph will be in a consistent state that LETO can interpret. Tinker with it at your own risk.","title":"\ud83d\udcdd User Guide"},{"location":"guide/#welcome-to-letos-user-guide","text":"This guide explains how to set up LETO and use its main application UI.","title":"Welcome to LETO's user guide"},{"location":"guide/#setting-up","text":"LETO comes packaged with a Docker environment ready to set up. To get started, you need to either clone the project from Github or obtain the source code via a different channel. Once you have the source code in place, cd into the project root and type: make app This command with launch three Docker containers: The main LETO application (\ud83d\udd17 http://localhost:8501 ) A neo4j instance where the backend data is stored (\ud83d\udd17 http://localhost:7474 ) A documentation server, like the one hosting these docs right now (\ud83d\udd17 http://localhost:8000 ) If you're deploying for a production environment, you'll probably want to set up a web server in front of the main application. In that case, you'd need to either modify docker/docker-compose.yml or create a new one (using that file as a starting point) and configure your web server accordingly.","title":"Setting up"},{"location":"guide/#overview-of-the-ui","text":"Below is a screenshot of the main LETO application. We'll guide you through the main components one at a time and how to use them.","title":"Overview of the UI"},{"location":"guide/#basic-configuration","text":"The top left panel is titled \"\u2699\ufe0f Config\". In this panel, you can configure the backend connection (either using neo4j or a dummy file-based storage driver) and the query parser . If you're using LETO in a language other than English, you will need an appropriate query parser. For now, LETO ships also with a Spanish parser, which you can select in the \"\ud83e\uddd9\u200d\u2642\ufe0f Query parser\" combo.","title":"\u2699\ufe0f Basic configuration"},{"location":"guide/#loading-data","text":"LETO runs on data, lots of data. To get data into LETO you'll need to supply one of several possible input types. The panel titled \"\ud83d\udd25 Load new data\" will let you select one of several Loaders that can introduce data to LETO from different formats. Currently, these are the options: Synthetic toy examples : A simple loader that creates a pre-defined small graph which you can use for illustrative purposes. Manually enter tuples : Allows you to explicitly define new entities and relations. From CSV files : Reads data from one or more CSV files, automatically inferring entities and relations based on some simple heuristics. From Text File : Reads natural language from a text file and detects entities and relations using NLP tools. From Plain Text : Same as the previous one, but you can directly type or paste in the text. From Wikipedia page : Given a query string for Wikipedia, this loader downloads the corresponding article and runs NLP tools to detect entities and relations. When you select one specific loader, the UI will change to show its configuration and input. For example, for the file-based loaders you will see a \"Browse files\" button that allows you to select CSV or text files from your filesystem.","title":"\ud83d\udd25 Loading data"},{"location":"guide/#queying-leto","text":"Once you have data in the system, LETO can start doing its magic. All the interaction with LETO is through natural language queries. You type a query in main the text input (\"\ud83d\udd2e Enter a query...\") and LETO will navigate through the information stored, collect the most relevant entities and relations for that query, and present that information in one of several formats. The most basic output, as shown in the image, is a subset of the knowledge graph that contains the relevant entities and relations. You will find the most important elements for the query highlighted in different color, e.g., the entities and relations that are explicitly mentioned or those which are very similar. According to the query and the information available, LETO will try to come up with interesting visualizations. For example if there's geographical information in the answer, you'll see it on a map. As an extreme example, a query like \"which features predict salary in Data Scientist\" will make LETO train a simple machine learning model on the available data and graph the feature importances for you.","title":"\ud83d\udd2e Queying LETO"},{"location":"guide/#example-queries","text":"If you've loaded the toy dataset (using the \"Synthetic toy examples\" loader), you can use one of the pre-defined queries at the right side of LETO's main UI. These are premade questions that illustrate the types of queries that can be posted to LETO.","title":"\u2753 Example queries"},{"location":"guide/#interacting-with-the-backend","text":"If you want to interact with the backend data, at http://localhost:7474 you will find neo4j's browser interface. To connect just enter the username neo4j and the password letoai . Neo4j is a graph database that powers all of LETO's queries. Refer to the official documentation for more information on how to use its interface directly. Warning Please keep in mind that if you modify the database outside of LETO (i.e., not using one of LETO's loaders), we cannot guarantee the graph will be in a consistent state that LETO can interpret. Tinker with it at your own risk.","title":"Interacting with the backend"},{"location":"tutorial/","text":"","title":"Tutorial"}]}