{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Welcome to the LETO MVP docs \u00b6 In this documentation, you will find the necessary instructions to set up and interact with the LETO application. Warning LETO is a work-in-progress, and it's currently not suitable for production use. Everything in this documentation can change at any time until the APIs are stable. Quick start \u00b6 The easiest way to get LETO up and running is to clone the source code repository and spin up the development environment. You will need docker and git installed. If you are on Linux, there's a makefile ready for you. $ git clone https://github.com/LETO-ai/leto-mvp $ make The previous command will spin up an instance of the LETO UI, the neo4j backend, and these docs. Then navigate to to interact with the UI. Note Refer to the user guide for details about using the application. Collaboration \u00b6 In LETO, we use trunk-based development. Developers use short-lived branches, which are pushed to the central repository and merged back to the main branch as quickly as possible. For development, you will need Visual Studio Code or another suitable editor. You will work in the development environment described in the previous section. Note Refer to the development guide for more details.","title":"\ud83c\udfe0 Home"},{"location":"#welcome-to-the-leto-mvp-docs","text":"In this documentation, you will find the necessary instructions to set up and interact with the LETO application. Warning LETO is a work-in-progress, and it's currently not suitable for production use. Everything in this documentation can change at any time until the APIs are stable.","title":"Welcome to the LETO MVP docs"},{"location":"#quick-start","text":"The easiest way to get LETO up and running is to clone the source code repository and spin up the development environment. You will need docker and git installed. If you are on Linux, there's a makefile ready for you. $ git clone https://github.com/LETO-ai/leto-mvp $ make The previous command will spin up an instance of the LETO UI, the neo4j backend, and these docs. Then navigate to to interact with the UI. Note Refer to the user guide for details about using the application.","title":"Quick start"},{"location":"#collaboration","text":"In LETO, we use trunk-based development. Developers use short-lived branches, which are pushed to the central repository and merged back to the main branch as quickly as possible. For development, you will need Visual Studio Code or another suitable editor. You will work in the development environment described in the previous section. Note Refer to the development guide for more details.","title":"Collaboration"},{"location":"dev/","text":"Welcome to LETO's development guide \u00b6 This guide explains LETO's architecture and guidelines on how to extend and modify it. Overview of LETO's architecture \u00b6 At the highest level, LETO is an application composed of two services: a frontend written in streamlit and a backend stored in neo4j . All the data is LETO is stored in a single graph database in neo4j , using some conventions to determine how it is interpreted. The frontend is a streamlit app which follows a very simple cycle: Load new data (if necessary) Parse a query Compute a response Visualize the response This cycle is implemented as a streamlined process in leto/ui.py which in turn uses several components to weave everything. Let's look at each step in more detail. Data enters LETO via a Loader , a class that implements a single _load() method that returns an iterable of Entity and Relation instances. An Entity is just a name plus a type, and some opaque attributes. Likewise, a Relation has a label, and the two entities it connects. All relations in LETO are directed. In the main application cycle, the currently selected loader is first instantiated with the corresponding parameters and then executed. The resulting iterable is given to a Storage instance, which can be either GraphStorage (the default) or a DummyStorage (which is there just for testing purposes). An Storage inheritor needs to supply a store method with receives either an entity or a relation. They also provide a size() method for instrospection. Once stored any newly created data, the main application loop proceeds to parse the current query. A QueryParser implementation is used here, which receives a string as input and returns an instance of the Query class. Different sub-instances of Query exist, but they all share the same basic structure: a list of entities, a list of relations, and a list of attributes. Currently implemented query parsers are based on some hard-coded rules on top of a spacy tokenization of the query, hence they perform basic entity detection and the rules are based on POS-tags and other syntactic cues. Once parsed, the query is fed to a QueryResolver instance, which is provided by the Storage implementation. This will return a sub-graph in the form of a list of tuples, i.e., Relation instances. How smart can this resolution be is left to the implementation of the query resolver. In GraphStorage the query resolver generates a set of neo4j queries based on some rules that try to find the most similar entities and relations in the graph. There's also currently a simplistic implementation of a similarity engine using spacy word embeddings, but this is still in a very crude state. Finally, the response (as a list of tuples) is fed to a list of Visualizer instances. Each visualizer has some specific rules that determine whether it applies, and if so, it produces a callable method to be run for generating the actual visualization. For example, the basic graph visualizer just outputs the graph as a pydot image. However, the map visualizer will inspect the tuples to see if it finds something with geographical information, and if so, it generates a map with the corresponding points. Adding new data sources \u00b6 To add a new data source, you need to provide a new implementation of Loader . As explained, this implementation must provide a _load() method which yields Entity or Relation instances one at a time. A Loader also provides a _get_source() method with outputs an entity of type Source . This basically holds metadata that is then linked to all the entities created from the _load() . As an example, here's a dummy implementation that loads data from a manually entered text in the format entity - relation - entity : class ManualLoader ( Loader ): @classmethod def title ( cls ): return \"Manually enter tuples\" def __init__ ( self , tuples : Text ) -> None : self . tuples = tuples def _get_source ( self , name , ** metadata ) -> Source : return Source ( name , method = \"manual\" , loader = \"ManualLoader\" , ** metadata ) def _load ( self ): for line in self . tuples . split ( \" \\n \" ): e1 , r , e2 = line . split ( \"-\" ) e1 = e1 . strip () r = r . strip () e2 = e2 . strip () yield Relation ( label = r , entity_from = Entity ( name = e1 , type = \"Thing\" ), entity_to = Entity ( name = e2 , type = \"Thing\" ), ) Finally, on leto/loaders/__init__.py , method get_loaders() , add a line importing your loader and include it into the returned list. Adding new visualizations \u00b6 To add a new visualization, you need to provide a new implementation of Visualizer . This implementation must provide a method visualize which in turn returns a Visualization instance. A visualization instance basically has title, a score, and a callable method that is invoked when the visualization must be executed. This callable will be run in a streamlit container context, so you can directly use st.* methods to construct any visualization logic you desire. The recommended approach is to implement whatever preprocessing logic is necessary in the visualize() method, and just perform actual visualization logic inside the callback. In the visualize() method, you'll have access to both the original query and the response. The score value is used to sort the visualizations, so you should set it to value that is roughly proportional to how informative the visualization is. This score is unbounded. Here's an example of a very simple visualizer: class DummyVisualizer ( Visualizer ): def visualize ( self , query : Query , response : List [ Relation ]) -> Visualization : def visualization (): st . code ( \" \\n \" . join ( str ( r ) for r in response )) return Visualization ( title = \"\ud83d\udccb Returned tuples\" , score = 0 , run = visualization ) Finally, on leto/visualization/__init__.py , method get_visualizers() add your implementation to the returned list.","title":"\ud83d\udee0\ufe0f Development Guide"},{"location":"dev/#welcome-to-letos-development-guide","text":"This guide explains LETO's architecture and guidelines on how to extend and modify it.","title":"Welcome to LETO's development guide"},{"location":"dev/#overview-of-letos-architecture","text":"At the highest level, LETO is an application composed of two services: a frontend written in streamlit and a backend stored in neo4j . All the data is LETO is stored in a single graph database in neo4j , using some conventions to determine how it is interpreted. The frontend is a streamlit app which follows a very simple cycle: Load new data (if necessary) Parse a query Compute a response Visualize the response This cycle is implemented as a streamlined process in leto/ui.py which in turn uses several components to weave everything. Let's look at each step in more detail. Data enters LETO via a Loader , a class that implements a single _load() method that returns an iterable of Entity and Relation instances. An Entity is just a name plus a type, and some opaque attributes. Likewise, a Relation has a label, and the two entities it connects. All relations in LETO are directed. In the main application cycle, the currently selected loader is first instantiated with the corresponding parameters and then executed. The resulting iterable is given to a Storage instance, which can be either GraphStorage (the default) or a DummyStorage (which is there just for testing purposes). An Storage inheritor needs to supply a store method with receives either an entity or a relation. They also provide a size() method for instrospection. Once stored any newly created data, the main application loop proceeds to parse the current query. A QueryParser implementation is used here, which receives a string as input and returns an instance of the Query class. Different sub-instances of Query exist, but they all share the same basic structure: a list of entities, a list of relations, and a list of attributes. Currently implemented query parsers are based on some hard-coded rules on top of a spacy tokenization of the query, hence they perform basic entity detection and the rules are based on POS-tags and other syntactic cues. Once parsed, the query is fed to a QueryResolver instance, which is provided by the Storage implementation. This will return a sub-graph in the form of a list of tuples, i.e., Relation instances. How smart can this resolution be is left to the implementation of the query resolver. In GraphStorage the query resolver generates a set of neo4j queries based on some rules that try to find the most similar entities and relations in the graph. There's also currently a simplistic implementation of a similarity engine using spacy word embeddings, but this is still in a very crude state. Finally, the response (as a list of tuples) is fed to a list of Visualizer instances. Each visualizer has some specific rules that determine whether it applies, and if so, it produces a callable method to be run for generating the actual visualization. For example, the basic graph visualizer just outputs the graph as a pydot image. However, the map visualizer will inspect the tuples to see if it finds something with geographical information, and if so, it generates a map with the corresponding points.","title":"Overview of LETO's architecture"},{"location":"dev/#adding-new-data-sources","text":"To add a new data source, you need to provide a new implementation of Loader . As explained, this implementation must provide a _load() method which yields Entity or Relation instances one at a time. A Loader also provides a _get_source() method with outputs an entity of type Source . This basically holds metadata that is then linked to all the entities created from the _load() . As an example, here's a dummy implementation that loads data from a manually entered text in the format entity - relation - entity : class ManualLoader ( Loader ): @classmethod def title ( cls ): return \"Manually enter tuples\" def __init__ ( self , tuples : Text ) -> None : self . tuples = tuples def _get_source ( self , name , ** metadata ) -> Source : return Source ( name , method = \"manual\" , loader = \"ManualLoader\" , ** metadata ) def _load ( self ): for line in self . tuples . split ( \" \\n \" ): e1 , r , e2 = line . split ( \"-\" ) e1 = e1 . strip () r = r . strip () e2 = e2 . strip () yield Relation ( label = r , entity_from = Entity ( name = e1 , type = \"Thing\" ), entity_to = Entity ( name = e2 , type = \"Thing\" ), ) Finally, on leto/loaders/__init__.py , method get_loaders() , add a line importing your loader and include it into the returned list.","title":"Adding new data sources"},{"location":"dev/#adding-new-visualizations","text":"To add a new visualization, you need to provide a new implementation of Visualizer . This implementation must provide a method visualize which in turn returns a Visualization instance. A visualization instance basically has title, a score, and a callable method that is invoked when the visualization must be executed. This callable will be run in a streamlit container context, so you can directly use st.* methods to construct any visualization logic you desire. The recommended approach is to implement whatever preprocessing logic is necessary in the visualize() method, and just perform actual visualization logic inside the callback. In the visualize() method, you'll have access to both the original query and the response. The score value is used to sort the visualizations, so you should set it to value that is roughly proportional to how informative the visualization is. This score is unbounded. Here's an example of a very simple visualizer: class DummyVisualizer ( Visualizer ): def visualize ( self , query : Query , response : List [ Relation ]) -> Visualization : def visualization (): st . code ( \" \\n \" . join ( str ( r ) for r in response )) return Visualization ( title = \"\ud83d\udccb Returned tuples\" , score = 0 , run = visualization ) Finally, on leto/visualization/__init__.py , method get_visualizers() add your implementation to the returned list.","title":"Adding new visualizations"},{"location":"guide/","text":"Welcome to LETO's user guide \u00b6 This guide explains how to set up LETO and use its main application UI. Setting up \u00b6 LETO comes packaged with a Docker environment ready to set up. To get started, you need to either clone the project from Github or obtain the source code via a different channel. Once you have the source code in place, cd into the project root and type: make app This command with launch three Docker containers: The main LETO application (\ud83d\udd17 http://localhost:8501 ) A neo4j instance where the backend data is stored (\ud83d\udd17 http://localhost:7474 ) A documentation server, like the one hosting these docs right now (\ud83d\udd17 http://localhost:8000 ) If you're deploying for a production environment, you'll probably want to set up a web server in front of the main application. In that case, you'd need to either modify docker/docker-compose.yml or create a new one (using that file as a starting point) and configure your web server accordingly. Overview of the UI \u00b6 Below is a screenshot of the main LETO application. We'll guide you through the main components one at a time and how to use them. \u2699\ufe0f Basic configuration \u00b6 The top left panel is titled \"\u2699\ufe0f Config\". In this panel, you can configure the backend connection (either using neo4j or a dummy file-based storage driver) and the query parser . If you're using LETO in a language other than English, you will need an appropriate query parser. For now, LETO ships also with a Spanish parser, which you can select in the \"\ud83e\uddd9\u200d\u2642\ufe0f Query parser\" combo. \ud83d\udd25 Loading data \u00b6 LETO runs on data, lots of data. To get data into LETO you'll need to supply one of several possible input types. The panel titled \"\ud83d\udd25 Load new data\" will let you select one of several Loaders that can introduce data to LETO from different formats. Currently, these are the options: Synthetic toy examples : A simple loader that creates a pre-defined small graph which you can use for illustrative purposes. Manually enter tuples : Allows you to explicitly define new entities and relations. From CSV files : Reads data from one or more CSV files, automatically inferring entities and relations based on some simple heuristics. From Text File : Reads natural language from a text file and detects entities and relations using NLP tools. From Plain Text : Same as the previous one, but you can directly type or paste in the text. From Wikipedia page : Given a query string for Wikipedia, this loader downloads the corresponding article and runs NLP tools to detect entities and relations. When you select one specific loader, the UI will change to show its configuration and input. For example, for the file-based loaders you will see a \"Browse files\" button that allows you to select CSV or text files from your filesystem. \ud83d\udd2e Queying LETO \u00b6 Once you have data in the system, LETO can start doing its magic. All the interaction with LETO is through natural language queries. You type a query in main the text input (\"\ud83d\udd2e Enter a query...\") and LETO will navigate through the information stored, collect the most relevant entities and relations for that query, and present that information in one of several formats. The most basic output, as shown in the image, is a subset of the knowledge graph that contains the relevant entities and relations. You will find the most important elements for the query highlighted in different color, e.g., the entities and relations that are explicitly mentioned or those which are very similar. According to the query and the information available, LETO will try to come up with interesting visualizations. For example if there's geographical information in the answer, you'll see it on a map. As an extreme example, a query like \"which features predict salary in Data Scientist\" will make LETO train a simple machine learning model on the available data and graph the feature importances for you. \u2753 Example queries \u00b6 If you've loaded the toy dataset (using the \"Synthetic toy examples\" loader), you can use one of the pre-defined queries at the right side of LETO's main UI. These are premade questions that illustrate the types of queries that can be posted to LETO. Interacting with the backend \u00b6 If you want to interact with the backend data, at http://localhost:7474 you will find neo4j's browser interface. To connect just enter the username neo4j and the password letoai . Neo4j is a graph database that powers all of LETO's queries. Refer to the official documentation for more information on how to use its interface directly. Warning Please keep in mind that if you modify the database outside of LETO (i.e., not using one of LETO's loaders), we cannot guarantee the graph will be in a consistent state that LETO can interpret. Tinker with it at your own risk.","title":"\ud83d\udcdd User Guide"},{"location":"guide/#welcome-to-letos-user-guide","text":"This guide explains how to set up LETO and use its main application UI.","title":"Welcome to LETO's user guide"},{"location":"guide/#setting-up","text":"LETO comes packaged with a Docker environment ready to set up. To get started, you need to either clone the project from Github or obtain the source code via a different channel. Once you have the source code in place, cd into the project root and type: make app This command with launch three Docker containers: The main LETO application (\ud83d\udd17 http://localhost:8501 ) A neo4j instance where the backend data is stored (\ud83d\udd17 http://localhost:7474 ) A documentation server, like the one hosting these docs right now (\ud83d\udd17 http://localhost:8000 ) If you're deploying for a production environment, you'll probably want to set up a web server in front of the main application. In that case, you'd need to either modify docker/docker-compose.yml or create a new one (using that file as a starting point) and configure your web server accordingly.","title":"Setting up"},{"location":"guide/#overview-of-the-ui","text":"Below is a screenshot of the main LETO application. We'll guide you through the main components one at a time and how to use them.","title":"Overview of the UI"},{"location":"guide/#basic-configuration","text":"The top left panel is titled \"\u2699\ufe0f Config\". In this panel, you can configure the backend connection (either using neo4j or a dummy file-based storage driver) and the query parser . If you're using LETO in a language other than English, you will need an appropriate query parser. For now, LETO ships also with a Spanish parser, which you can select in the \"\ud83e\uddd9\u200d\u2642\ufe0f Query parser\" combo.","title":"\u2699\ufe0f Basic configuration"},{"location":"guide/#loading-data","text":"LETO runs on data, lots of data. To get data into LETO you'll need to supply one of several possible input types. The panel titled \"\ud83d\udd25 Load new data\" will let you select one of several Loaders that can introduce data to LETO from different formats. Currently, these are the options: Synthetic toy examples : A simple loader that creates a pre-defined small graph which you can use for illustrative purposes. Manually enter tuples : Allows you to explicitly define new entities and relations. From CSV files : Reads data from one or more CSV files, automatically inferring entities and relations based on some simple heuristics. From Text File : Reads natural language from a text file and detects entities and relations using NLP tools. From Plain Text : Same as the previous one, but you can directly type or paste in the text. From Wikipedia page : Given a query string for Wikipedia, this loader downloads the corresponding article and runs NLP tools to detect entities and relations. When you select one specific loader, the UI will change to show its configuration and input. For example, for the file-based loaders you will see a \"Browse files\" button that allows you to select CSV or text files from your filesystem.","title":"\ud83d\udd25 Loading data"},{"location":"guide/#queying-leto","text":"Once you have data in the system, LETO can start doing its magic. All the interaction with LETO is through natural language queries. You type a query in main the text input (\"\ud83d\udd2e Enter a query...\") and LETO will navigate through the information stored, collect the most relevant entities and relations for that query, and present that information in one of several formats. The most basic output, as shown in the image, is a subset of the knowledge graph that contains the relevant entities and relations. You will find the most important elements for the query highlighted in different color, e.g., the entities and relations that are explicitly mentioned or those which are very similar. According to the query and the information available, LETO will try to come up with interesting visualizations. For example if there's geographical information in the answer, you'll see it on a map. As an extreme example, a query like \"which features predict salary in Data Scientist\" will make LETO train a simple machine learning model on the available data and graph the feature importances for you.","title":"\ud83d\udd2e Queying LETO"},{"location":"guide/#example-queries","text":"If you've loaded the toy dataset (using the \"Synthetic toy examples\" loader), you can use one of the pre-defined queries at the right side of LETO's main UI. These are premade questions that illustrate the types of queries that can be posted to LETO.","title":"\u2753 Example queries"},{"location":"guide/#interacting-with-the-backend","text":"If you want to interact with the backend data, at http://localhost:7474 you will find neo4j's browser interface. To connect just enter the username neo4j and the password letoai . Neo4j is a graph database that powers all of LETO's queries. Refer to the official documentation for more information on how to use its interface directly. Warning Please keep in mind that if you modify the database outside of LETO (i.e., not using one of LETO's loaders), we cannot guarantee the graph will be in a consistent state that LETO can interpret. Tinker with it at your own risk.","title":"Interacting with the backend"},{"location":"tutorial/","text":"Welcome to LETO's Tutorial \u00b6 This tutorial will guide you through the usage of LETO in a specific example domain. The domain in question is about the province of Alicante, Spain, and mostly related to tourism information. Warning Make sure to clear the database (button \ud83d\udca3 Clear database ) before following this tutorial, so that you start from scratch. Loading the first data set \u00b6 The first data set we will analyze is related with some touristic locations in Alicante. To begin, download the CSV file locations_alicante.csv here . If you open the file, you'll see something like the following: location , lat , lon , country , province Albir , 38.570982499565076 , - 0.07026377183837483 , Spain , Alicante Alcampo , 38.36708247502724 , - 0.4699022752090634 , Spain , Alicante Avenida Jovellanas , 38.34789006276749 , - 0.4755058728788782 , Spain , Alicante Castillo de Alicante , 38.349140160469716 , - 0.4780181728788511 , Spain , Alicante Castillo de Santa B\u00e1rbara , 38.349140160469716 , - 0.4780181728788511 , Spain , Alicante Ciudad de la Luz , 38.364444444444445 , - 0.43833333333333335 , Spain , Alicante El Corte Ingl\u00e9s , 38.347524302739636 , - 0.48798528517226725 , Spain , Alicante ... This file contains structured information about some locations, including latitude and longitude. We'll feed LETO with this information to begin. On the right side panel, under the \ud83d\udd25 Load data panel, select the loader named From CSV files . Click the Browse button and select the file you just downloaded ( locations_alicante.csv ). Then hit \ud83d\ude80 Run . You should see a small green message at the bottom that says \"Succesfully loaded...\". This means the data was correctly loaded. Check the following image for reference: Exploring the data \u00b6 Now that we have some data, let's run some queries. Start by typing alicante into the query textbox and see what happens. You should see something like the following image: This graph represents a small context around the entity Alicante , which is the most similar entity to our input query alicante . You can see there are some locations that are related with Alicante and Spain . You can zoom, move, and otherwise interact with the graph to better explore it. If you hover over any of the nodes you'll see some relevant metadata: Scrolling down you'll find additional visualizations about the subgraph that's being displayed. For example, you'll see a pie chart with the distribution of the locations that exist in the graph: Loading semi-structured data \u00b6 Next, we want to enrich this information with another dataset, this time a CSV file that contains comments extracted from social media that mention some of the locations present in the graph. To do that, download the CSV file named comments_alicante.csv here . The file looks something like this: comment : text , rating , date , likes , source , query : text , country \"Alicante sorprende por su buen clima...\" , 5 , 2010 - 10 - 31 , 2 , TripAdvisor , Alicante , Spain \"Estuvimos en Alicante. Hotel LA CITY...\" , 5 , 2010 - 10 - 03 , 0 , TripAdvisor , Alicante , Argentina \"El personal era realmente acogedor, ...\" , 5 , 2010 - 12 - 04 , 3 , TripAdvisor , Alicante , United Kingdom The first column contains a natural language text with comments, and the rest are structured information. You'll notice that some columns are explicitely marked with a semantic tag ( :text ) to tell LETO how to treat these columns. By default, LETO will try to infer if a column corresponds to an attribute, an entity, or a relation. To do so, it relies on some heuristics about the structure of the data. For example, columns that are unique short labels are taken as possible entity ids, while numbers and dates are taken as attributes. In this case, we are telling LETO to explicitly interpret comment and query as text rather than, say, an entity label. We will this CSV as before using the \ud83d\udd25 Load data panel but we will explicitely define a name for the type of entity that will be created. In this case, we want each row in this CSV to be associated with an entity of type Comment , so we set the value of main_entity to Comment , just like the following image (also, make sure there's only one CSV selected and that language is set to es ): Go ahead and hit \ud83d\ude80 Run . Exploring the new data \u00b6 Immediately after loading the new data you'll notice that the same query alicante now returns a slightly different graph (your colors may vary): You'll see new Comment nodes that represent each of the lines in the CSV, along with their associated metadata (such as rating and date ). Furthermore, each Comment node is related with some of the existing locations via a mention relation. This is because LETO performs some smart natural language processing to detect entities in text fields (such as comment ) and automatically creates the corresponding relations to the associated semantic entities. To make it more interesting, type alicante mentions in the query box. This has the effect of showing the same graph, but now the locations are displayed in a map: This happens because the query now identifies the mention relationship explicitely, and thus the entities participating in that relationship are subject to visualization, and they happen to have location information associated with them. To make it even more interesting let's try to compare the ratings of comments by location. Write the following query, alicante ratings by location , and you should see something like the following: The magic happening here is that LETO will scan the graph looking for an attribute called rating in an object related with something of type Location . Similarly, you can try alicante likes by location and you'll see a similar graph. You can even combine both queries in alicante ratings and likes by location and you'll see both graphs: Adding time-indexed data \u00b6 Next, we will add another CSV that contains time-indexed information. Download the file named tourism_spain.csv here and load it into LETO. Se the main_entity label to TourismInfo . The data looks something like this: country , date , tourists Spain , 2020 - 12 , 648989 Spain , 2020 - 11 , 456814 Spain , 2020 - 10 , 1020773 Spain , 2020 - 09 , 1138868 Now type spain in the query box to see what happens. The graph will look something like the following, to reflect the facts that we know about Spain , including the previous entities and a new set of TourismInfo nodes that represent the data in the new CSV: Now type spain tourists by country and you should see a timeseries graph like the following: The magic here happens because there's a date attribute on the TourismInfo node, and it's associated via a country relation with the entities you mention. By understanding how LETO interprets a query, we can tinker with the input to achieve more or less what we want. Loading a large data set \u00b6 Let's now load the file employment_alicante.csv located here , which also contains time-indexed information about unemployment in a sample of municipalities inside Alicante. Make sure to set the main_entity to UnemploymentInfo . The file looks something like this: municipality : rel , province : rel , country : rel , age : attr , gender : rel , unemployment , date Altea , Alicante , Spain , < 25 , Masculino , 34.0 , 06 / 01 / 01 Altea , Alicante , Spain , 25 - 44 , Masculino , 123.0 , 06 / 01 / 01 Altea , Alicante , Spain , >= 45 , Masculino , 0.0 , 06 / 01 / 01 Altea , Alicante , Spain , < 25 , Femenino , 87.0 , 06 / 01 / 01 Altea , Alicante , Spain , 25 - 44 , Femenino , 41.0 , 06 / 01 / 01 Altea , Alicante , Spain , >= 45 , Femenino , 257.0 , 06 / 01 / 01 Benidorm , Alicante , Spain , < 25 , Masculino , 211.0 , 06 / 01 / 01 Benidorm , Alicante , Spain , 25 - 44 , Masculino , 763.0 , 06 / 01 / 01 Benidorm , Alicante , Spain , >= 45 , Masculino , 0.0 , 06 / 01 / 01 Benidorm , Alicante , Spain , < 25 , Femenino , 479.0 , 06 / 01 / 01 Benidorm , Alicante , Spain , 25 - 44 , Femenino , 172.0 , 06 / 01 / 01 Benidorm , Alicante , Spain , >= 45 , Femenino , 1033.0 , 06 / 01 / 01 As you can see, there are several :rel annotations which indicate LETO that we want those columns to become explicit relations with an entity rather than simple attributes. Go ahead and load the data if you haven't. This is a bigger file which can take a couple minutes to fully digest. Once loaded you'll see a bunch of new facts (around ~11K) have appeared in the \u2699\ufe0f Config panel. If you just type alicante in the query box you'll get a graph like the following: Having this much data creates a couple of problems we'll have to deal with. First, if you just type alicante you'll never recover the comments, for example, because there's so much unemployment info that any subsample of the graph around Alicante is unlikely to have anything else. To deal with this issue, you can type alicante ~unemploymentinfo to create a negative filter that will ignore all UnemploymentInfo nodes and give you back the old graph. The second issue has to do with the size of the subgraph recovered. If you type alicante unemployment by municipality ~location you'll see that it selects some of the relevant data: However, since LETO returns a subset of the graph, not necessarily all the data available will be included in the graph. To fix this, you can enter a larger number for the \ud83d\udd2e Max results field in the \u2699\ufe0f Config panel. Enter 10000 to see how the whole of the data looks like. The caveat is that with such a big graph, LETO will not show the graph representation.","title":"\u2753 Tutorial"},{"location":"tutorial/#welcome-to-letos-tutorial","text":"This tutorial will guide you through the usage of LETO in a specific example domain. The domain in question is about the province of Alicante, Spain, and mostly related to tourism information. Warning Make sure to clear the database (button \ud83d\udca3 Clear database ) before following this tutorial, so that you start from scratch.","title":"Welcome to LETO's Tutorial"},{"location":"tutorial/#loading-the-first-data-set","text":"The first data set we will analyze is related with some touristic locations in Alicante. To begin, download the CSV file locations_alicante.csv here . If you open the file, you'll see something like the following: location , lat , lon , country , province Albir , 38.570982499565076 , - 0.07026377183837483 , Spain , Alicante Alcampo , 38.36708247502724 , - 0.4699022752090634 , Spain , Alicante Avenida Jovellanas , 38.34789006276749 , - 0.4755058728788782 , Spain , Alicante Castillo de Alicante , 38.349140160469716 , - 0.4780181728788511 , Spain , Alicante Castillo de Santa B\u00e1rbara , 38.349140160469716 , - 0.4780181728788511 , Spain , Alicante Ciudad de la Luz , 38.364444444444445 , - 0.43833333333333335 , Spain , Alicante El Corte Ingl\u00e9s , 38.347524302739636 , - 0.48798528517226725 , Spain , Alicante ... This file contains structured information about some locations, including latitude and longitude. We'll feed LETO with this information to begin. On the right side panel, under the \ud83d\udd25 Load data panel, select the loader named From CSV files . Click the Browse button and select the file you just downloaded ( locations_alicante.csv ). Then hit \ud83d\ude80 Run . You should see a small green message at the bottom that says \"Succesfully loaded...\". This means the data was correctly loaded. Check the following image for reference:","title":"Loading the first data set"},{"location":"tutorial/#exploring-the-data","text":"Now that we have some data, let's run some queries. Start by typing alicante into the query textbox and see what happens. You should see something like the following image: This graph represents a small context around the entity Alicante , which is the most similar entity to our input query alicante . You can see there are some locations that are related with Alicante and Spain . You can zoom, move, and otherwise interact with the graph to better explore it. If you hover over any of the nodes you'll see some relevant metadata: Scrolling down you'll find additional visualizations about the subgraph that's being displayed. For example, you'll see a pie chart with the distribution of the locations that exist in the graph:","title":"Exploring the data"},{"location":"tutorial/#loading-semi-structured-data","text":"Next, we want to enrich this information with another dataset, this time a CSV file that contains comments extracted from social media that mention some of the locations present in the graph. To do that, download the CSV file named comments_alicante.csv here . The file looks something like this: comment : text , rating , date , likes , source , query : text , country \"Alicante sorprende por su buen clima...\" , 5 , 2010 - 10 - 31 , 2 , TripAdvisor , Alicante , Spain \"Estuvimos en Alicante. Hotel LA CITY...\" , 5 , 2010 - 10 - 03 , 0 , TripAdvisor , Alicante , Argentina \"El personal era realmente acogedor, ...\" , 5 , 2010 - 12 - 04 , 3 , TripAdvisor , Alicante , United Kingdom The first column contains a natural language text with comments, and the rest are structured information. You'll notice that some columns are explicitely marked with a semantic tag ( :text ) to tell LETO how to treat these columns. By default, LETO will try to infer if a column corresponds to an attribute, an entity, or a relation. To do so, it relies on some heuristics about the structure of the data. For example, columns that are unique short labels are taken as possible entity ids, while numbers and dates are taken as attributes. In this case, we are telling LETO to explicitly interpret comment and query as text rather than, say, an entity label. We will this CSV as before using the \ud83d\udd25 Load data panel but we will explicitely define a name for the type of entity that will be created. In this case, we want each row in this CSV to be associated with an entity of type Comment , so we set the value of main_entity to Comment , just like the following image (also, make sure there's only one CSV selected and that language is set to es ): Go ahead and hit \ud83d\ude80 Run .","title":"Loading semi-structured data"},{"location":"tutorial/#exploring-the-new-data","text":"Immediately after loading the new data you'll notice that the same query alicante now returns a slightly different graph (your colors may vary): You'll see new Comment nodes that represent each of the lines in the CSV, along with their associated metadata (such as rating and date ). Furthermore, each Comment node is related with some of the existing locations via a mention relation. This is because LETO performs some smart natural language processing to detect entities in text fields (such as comment ) and automatically creates the corresponding relations to the associated semantic entities. To make it more interesting, type alicante mentions in the query box. This has the effect of showing the same graph, but now the locations are displayed in a map: This happens because the query now identifies the mention relationship explicitely, and thus the entities participating in that relationship are subject to visualization, and they happen to have location information associated with them. To make it even more interesting let's try to compare the ratings of comments by location. Write the following query, alicante ratings by location , and you should see something like the following: The magic happening here is that LETO will scan the graph looking for an attribute called rating in an object related with something of type Location . Similarly, you can try alicante likes by location and you'll see a similar graph. You can even combine both queries in alicante ratings and likes by location and you'll see both graphs:","title":"Exploring the new data"},{"location":"tutorial/#adding-time-indexed-data","text":"Next, we will add another CSV that contains time-indexed information. Download the file named tourism_spain.csv here and load it into LETO. Se the main_entity label to TourismInfo . The data looks something like this: country , date , tourists Spain , 2020 - 12 , 648989 Spain , 2020 - 11 , 456814 Spain , 2020 - 10 , 1020773 Spain , 2020 - 09 , 1138868 Now type spain in the query box to see what happens. The graph will look something like the following, to reflect the facts that we know about Spain , including the previous entities and a new set of TourismInfo nodes that represent the data in the new CSV: Now type spain tourists by country and you should see a timeseries graph like the following: The magic here happens because there's a date attribute on the TourismInfo node, and it's associated via a country relation with the entities you mention. By understanding how LETO interprets a query, we can tinker with the input to achieve more or less what we want.","title":"Adding time-indexed data"},{"location":"tutorial/#loading-a-large-data-set","text":"Let's now load the file employment_alicante.csv located here , which also contains time-indexed information about unemployment in a sample of municipalities inside Alicante. Make sure to set the main_entity to UnemploymentInfo . The file looks something like this: municipality : rel , province : rel , country : rel , age : attr , gender : rel , unemployment , date Altea , Alicante , Spain , < 25 , Masculino , 34.0 , 06 / 01 / 01 Altea , Alicante , Spain , 25 - 44 , Masculino , 123.0 , 06 / 01 / 01 Altea , Alicante , Spain , >= 45 , Masculino , 0.0 , 06 / 01 / 01 Altea , Alicante , Spain , < 25 , Femenino , 87.0 , 06 / 01 / 01 Altea , Alicante , Spain , 25 - 44 , Femenino , 41.0 , 06 / 01 / 01 Altea , Alicante , Spain , >= 45 , Femenino , 257.0 , 06 / 01 / 01 Benidorm , Alicante , Spain , < 25 , Masculino , 211.0 , 06 / 01 / 01 Benidorm , Alicante , Spain , 25 - 44 , Masculino , 763.0 , 06 / 01 / 01 Benidorm , Alicante , Spain , >= 45 , Masculino , 0.0 , 06 / 01 / 01 Benidorm , Alicante , Spain , < 25 , Femenino , 479.0 , 06 / 01 / 01 Benidorm , Alicante , Spain , 25 - 44 , Femenino , 172.0 , 06 / 01 / 01 Benidorm , Alicante , Spain , >= 45 , Femenino , 1033.0 , 06 / 01 / 01 As you can see, there are several :rel annotations which indicate LETO that we want those columns to become explicit relations with an entity rather than simple attributes. Go ahead and load the data if you haven't. This is a bigger file which can take a couple minutes to fully digest. Once loaded you'll see a bunch of new facts (around ~11K) have appeared in the \u2699\ufe0f Config panel. If you just type alicante in the query box you'll get a graph like the following: Having this much data creates a couple of problems we'll have to deal with. First, if you just type alicante you'll never recover the comments, for example, because there's so much unemployment info that any subsample of the graph around Alicante is unlikely to have anything else. To deal with this issue, you can type alicante ~unemploymentinfo to create a negative filter that will ignore all UnemploymentInfo nodes and give you back the old graph. The second issue has to do with the size of the subgraph recovered. If you type alicante unemployment by municipality ~location you'll see that it selects some of the relevant data: However, since LETO returns a subset of the graph, not necessarily all the data available will be included in the graph. To fix this, you can enter a larger number for the \ud83d\udd2e Max results field in the \u2699\ufe0f Config panel. Enter 10000 to see how the whole of the data looks like. The caveat is that with such a big graph, LETO will not show the graph representation.","title":"Loading a large data set"}]}